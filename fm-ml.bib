% Encoding: UTF-8

@InCollection{scott2021machsmt,
  author    = {Joseph Scott and Aina Niemetz and Mathias Preiner and Saeed Nejati and Vijay Ganesh},
  booktitle = {Tools and Algorithms for the Construction and Analysis of Systems},
  publisher = {Springer International Publishing},
  title     = {{MachSMT}: A Machine Learning-based Algorithm Selector for {SMT} Solvers},
  year      = {2021},
  pages     = {303--325},
  doi       = {10.1007/978-3-030-72013-1_16},
  groups    = {Tool and Configuration Selection},
}

@InCollection{dunkelau2019automated,
  author    = {Jannik Dunkelau and Sebastian Krings and Joshua Schmidt},
  booktitle = {Lecture Notes in Computer Science},
  publisher = {Springer International Publishing},
  title     = {Automated Backend Selection for {ProB} Using Deep Learning},
  year      = {2019},
  pages     = {130--147},
  doi       = {10.1007/978-3-030-20652-9_9},
  groups    = {Tool and Configuration Selection},
}

@InProceedings{nagashima2018pamper,
  author    = {Yutaka Nagashima and Yilun He},
  booktitle = {Proceedings of the 33rd {ACM}/{IEEE} International Conference on Automated Software Engineering},
  title     = {{PaMpeR}: proof method recommendation system for Isabelle/{HOL}},
  year      = {2018},
  month     = {sep},
  publisher = {{ACM}},
  doi       = {10.1145/3238147.3238210},
  groups    = {Tool and Configuration Selection},
}

@Article{healy2017predicting,
  author    = {Andrew Healy and Rosemary Monahan and James F. Power},
  journal   = {Electronic Proceedings in Theoretical Computer Science},
  title     = {Predicting {SMT} Solver Performance for Software Verification},
  year      = {2017},
  month     = {jan},
  pages     = {20--37},
  volume    = {240},
  doi       = {10.4204/eptcs.240.2},
  groups    = {Tool and Configuration Selection},
  publisher = {Open Publishing Association},
}

@InProceedings{healy2016evaluating,
  author    = {Andrew Healy and Rosemary Monahan and James F. Power},
  booktitle = {Proceedings of the 31st Annual {ACM} Symposium on Applied Computing},
  title     = {Evaluating the use of a general-purpose benchmark suite for domain-specific {SMT}-solving},
  year      = {2016},
  month     = {apr},
  publisher = {{ACM}},
  doi       = {10.1145/2851613.2851975},
  groups    = {Tool and Configuration Selection},
}

@InProceedings{tulsian2014mux,
  author    = {Varun Tulsian and Aditya Kanade and Rahul Kumar and Akash Lal and Aditya V. Nori},
  booktitle = {Proceedings of the 11th Working Conference on Mining Software Repositories - {MSR} 2014},
  title     = {{MUX}: algorithm selection for software model checkers},
  year      = {2014},
  publisher = {{ACM} Press},
  doi       = {10.1145/2597073.2597080},
  groups    = {Tool and Configuration Selection},
}

@Article{hutter2009paramils,
  author    = {F. Hutter and H. H. Hoos and K. Leyton-Brown and T. Stuetzle},
  journal   = {Journal of Artificial Intelligence Research},
  title     = {{ParamILS}: An Automatic Algorithm Configuration Framework},
  year      = {2009},
  month     = {oct},
  pages     = {267--306},
  volume    = {36},
  doi       = {10.1613/jair.2861},
  groups    = {Tool and Configuration Selection},
  publisher = {{AI} Access Foundation},
}

@TechReport{UCAM-CL-TR-792,
  author      = {Bridge, James P.},
  institution = {University of Cambridge, Computer Laboratory},
  title       = {{Machine learning and automated theorem proving}},
  year        = {2010},
  month       = nov,
  number      = {UCAM-CL-TR-792},
  doi         = {10.48456/tr-792},
  groups      = {Tool and Configuration Selection},
  url         = {https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-792.pdf},
}

@Article{cai2019automatic,
  author    = {Cheng-Hao Cai and Jing Sun and Gillian Dobbie},
  journal   = {Automated Software Engineering},
  title     = {Automatic B-model repair using model checking and machine learning},
  year      = {2019},
  month     = {aug},
  number    = {3},
  pages     = {653--704},
  volume    = {26},
  doi       = {10.1007/s10515-019-00264-4},
  groups    = {Synthesis and Repair},
  publisher = {Springer Science and Business Media {LLC}},
}

@InCollection{schmidt2018repair,
  author    = {Joshua Schmidt and Sebastian Krings and Michael Leuschel},
  booktitle = {Lecture Notes in Computer Science},
  publisher = {Springer International Publishing},
  title     = {Repair and Generation of Formal Models Using Synthesis},
  year      = {2018},
  pages     = {346--366},
  doi       = {10.1007/978-3-319-98938-9_20},
  groups    = {Synthesis and Repair},
}

@Article{claessen2017supervisory,
  author        = {Koen Claessen and Jonatan Kilhamn and Laura Kov√°cs and Bengt Lennartson},
  journal       = {Strichman O., Tzoref-Brill R. (eds) Hardware and Software: Verification and Testing. HVC 2017. Lecture Notes in Computer Science, vol 10629. Springer, Cham},
  title         = {A Supervisory Control Algorithm Based on Property-Directed Reachability},
  year          = {2017},
  month         = nov,
  abstract      = {We present an algorithm for synthesising a controller (supervisor) for a discrete event system (DES) based on the property-directed reachability (PDR) model checking algorithm. The discrete event systems framework is useful in both software, automation and manufacturing, as problems from those domains can be modelled as discrete supervisory control problems. As a formal framework, DES is also similar to domains for which the field of formal methods for computer science has developed techniques and tools. In this paper, we attempt to marry the two by adapting PDR to the problem of controller synthesis. The resulting algorithm takes as input a transition system with forbidden states and uncontrollable transitions, and synthesises a safe and minimally-restrictive controller, correct-by-design. We also present an implementation along with experimental results, showing that the algorithm has potential as a part of the solution to the greater effort of formal supervisory controller synthesis and verification.},
  archiveprefix = {arXiv},
  doi           = {10.1007/978-3-319-70389-3_8},
  eprint        = {1711.06501},
  file          = {:http\://arxiv.org/pdf/1711.06501v1:PDF},
  groups        = {Synthesis and Repair},
  keywords      = {cs.SY, cs.LO, 68-02},
  primaryclass  = {cs.SY},
}

@Article{jha2017theory,
  author    = {Susmit Jha and Sanjit A. Seshia},
  journal   = {Acta Informatica},
  title     = {A theory of formal synthesis via inductive learning},
  year      = {2017},
  month     = {feb},
  number    = {7},
  pages     = {693--726},
  volume    = {54},
  doi       = {10.1007/s00236-017-0294-5},
  groups    = {Synthesis and Repair},
  publisher = {Springer Science and Business Media {LLC}},
}

@InCollection{katzmodel,
  author    = {Gal Katz and Doron Peled},
  booktitle = {Tools and Algorithms for the Construction and Analysis of Systems},
  publisher = {Springer Berlin Heidelberg},
  title     = {Model Checking-Based Genetic Programming with an Application to Mutual Exclusion},
  pages     = {141--156},
  doi       = {10.1007/978-3-540-78800-3_11},
  groups    = {Synthesis and Repair},
}

@InCollection{szegedy2020promising,
  author    = {Christian Szegedy},
  booktitle = {Lecture Notes in Computer Science},
  publisher = {Springer International Publishing},
  title     = {A Promising Path Towards Autoformalization and General Artificial Intelligence},
  year      = {2020},
  pages     = {3--20},
  doi       = {10.1007/978-3-030-53518-6_1},
  groups    = {Formalisation and Specifications},
}

@InProceedings{rahman2019classifying,
  author    = {Md. Abdur Rahman and Md. Ariful Haque and Md. Nurul Ahad Tawhid and Md. Saeed Siddik},
  booktitle = {Proceedings of the 3rd {ACM} {SIGSOFT} International Workshop on Machine Learning Techniques for Software Quality Evaluation - {MaLTeSQuE} 2019},
  title     = {Classifying non-functional requirements using {RNN} variants for quality software development},
  year      = {2019},
  publisher = {{ACM} Press},
  doi       = {10.1145/3340482.3342745},
  groups    = {Formalisation and Specifications},
}

@InProceedings{sharma2014machine,
  author    = {Richa Sharma and Jaspreet Bhatia and K. K. Biswas},
  booktitle = {Proceedings of the 3rd International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering - {RAISE} 2014},
  title     = {Machine learning for constituency test of coordinating conjunctions in requirements specifications},
  year      = {2014},
  publisher = {{ACM} Press},
  doi       = {10.1145/2593801.2593806},
  groups    = {Formalisation and Specifications},
}

@InProceedings{sultanov2013application,
  author    = {Hakim Sultanov and Jane Huffman Hayes},
  booktitle = {2013 21st {IEEE} International Requirements Engineering Conference ({RE})},
  title     = {Application of reinforcement learning to requirements engineering: requirements tracing},
  year      = {2013},
  month     = {jul},
  publisher = {{IEEE}},
  doi       = {10.1109/re.2013.6636705},
  groups    = {Formalisation and Specifications},
}

@InProceedings{kaliszyk2015efficient,
  author    = {Kaliszyk, Cezary and Urban, Josef and Vyskocil, Jir{\'\i}},
  booktitle = {Twenty-Fourth International Joint Conference on Artificial Intelligence},
  title     = {Efficient Semantic Features for Automated Reasoning over Large Theories},
  year      = {2015},
  eprint    = {file:///tmp/mozilla_jannik0/11384-49917-1-PB.pdf},
  groups    = {Feature Selection},
}

@InCollection{dunkelau2020analysing,
  author    = {Jannik Dunkelau and Joshua Schmidt and Michael Leuschel},
  booktitle = {Rigorous State-Based Methods},
  publisher = {Springer International Publishing},
  title     = {Analysing {ProB}'s Constraint Solving Backends},
  year      = {2020},
  pages     = {107--123},
  doi       = {10.1007/978-3-030-48077-6_8},
  groups    = {Tooling Analysis and Data Mining},
}

@Article{pira2021using,
  author    = {Einollah Pira},
  journal   = {Software Quality Journal},
  title     = {Using knowledge discovery to propose a two-phase model checking for safety analysis of graph transformations},
  year      = {2021},
  month     = {feb},
  doi       = {10.1007/s11219-020-09542-x},
  groups    = {Model Checking},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{zhu2019ltl,
  author    = {Weijun Zhu and Huanmei Wu and Miaolei Deng},
  journal   = {{IEEE} Access},
  title     = {{LTL} Model Checking Based on Binary Classification of Machine Learning},
  year      = {2019},
  pages     = {135703--135719},
  volume    = {7},
  doi       = {10.1109/access.2019.2942762},
  groups    = {Model Checking},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@InCollection{bortolussi2015machine,
  author    = {Luca Bortolussi and Dimitrios Milios and Guido Sanguinetti},
  booktitle = {Runtime Verification},
  publisher = {Springer International Publishing},
  title     = {Machine Learning Methods in Statistical Model Checking and System Design {\textendash} Tutorial},
  year      = {2015},
  pages     = {323--341},
  doi       = {10.1007/978-3-319-23820-3_23},
  groups    = {Model Checking},
}

@InCollection{brazdil2014verification,
  author    = {Tom{\'{a}}{\v{s}} Br{\'{a}}zdil and Krishnendu Chatterjee and Martin Chmel{\'{\i}}k and Vojt{\v{e}}ch Forejt and Jan K{\v{r}}et{\'{\i}}nsk{\'{y}} and Marta Kwiatkowska and David Parker and Mateusz Ujma},
  booktitle = {Automated Technology for Verification and Analysis},
  publisher = {Springer International Publishing},
  title     = {Verification of Markov Decision Processes Using Learning Algorithms},
  year      = {2014},
  pages     = {98--114},
  doi       = {10.1007/978-3-319-11936-6_8},
  groups    = {Model Checking},
}

@InProceedings{poulding2015heuristic,
  author    = {Simon Poulding and Robert Feldt},
  booktitle = {Proceedings of the 2015 Annual Conference on Genetic and Evolutionary Computation},
  title     = {Heuristic Model Checking using a Monte-Carlo Tree Search Algorithm},
  year      = {2015},
  month     = {jul},
  publisher = {{ACM}},
  doi       = {10.1145/2739480.2754767},
  groups    = {Model Checking},
}

@Article{yousefian2014heuristic,
  author    = {Rosa Yousefian and Vahid Rafe and Mohsen Rahmani},
  journal   = {Applied Soft Computing},
  title     = {A heuristic solution for model checking graph transformation systems},
  year      = {2014},
  month     = {nov},
  pages     = {169--180},
  volume    = {24},
  doi       = {10.1016/j.asoc.2014.06.055},
  groups    = {Model Checking},
  publisher = {Elsevier {BV}},
}

@InCollection{behjati2010bounded,
  author    = {Razieh Behjati and Marjan Sirjani and Majid Nili Ahmadabadi},
  booktitle = {Fundamentals of Software Engineering},
  publisher = {Springer Berlin Heidelberg},
  title     = {Bounded Rational Search for On-the-Fly Model Checking of {LTL} Properties},
  year      = {2010},
  pages     = {292--307},
  doi       = {10.1007/978-3-642-11623-0_17},
  groups    = {Model Checking},
}

@InProceedings{alba2008finding,
  author    = {Enrique Alba and Francisco Chicano and Marco Ferreira and Juan Gomez-Pulido},
  booktitle = {Proceedings of the 10th annual conference on Genetic and evolutionary computation - {GECCO} {\textquotesingle}08},
  title     = {Finding deadlocks in large concurrent java programs using genetic algorithms},
  year      = {2008},
  publisher = {{ACM} Press},
  doi       = {10.1145/1389095.1389432},
  groups    = {Model Checking},
}

@Article{godefroid2004exploring,
  author    = {Patrice Godefroid and Sarfraz Khurshid},
  journal   = {International Journal on Software Tools for Technology Transfer},
  title     = {Exploring very large state spaces using genetic algorithms},
  year      = {2004},
  month     = {apr},
  number    = {2},
  pages     = {117--127},
  volume    = {6},
  doi       = {10.1007/s10009-004-0141-1},
  groups    = {Model Checking},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{buccafurri1999enhancing,
  author    = {Francesco Buccafurri and Thomas Eiter and Georg Gottlob and Nicola Leone},
  journal   = {Artificial Intelligence},
  title     = {Enhancing model checking in verification by {AI} techniques},
  year      = {1999},
  month     = {aug},
  number    = {1-2},
  pages     = {57--104},
  volume    = {112},
  doi       = {10.1016/s0004-3702(99)00039-9},
  groups    = {Model Checking},
  publisher = {Elsevier {BV}},
}

@Article{hasanbeig2018logically,
  author        = {Mohammadhosein Hasanbeig and Alessandro Abate and Daniel Kroening},
  title         = {Logically-Constrained Reinforcement Learning},
  year          = {2018},
  month         = jan,
  abstract      = {We present the first model-free Reinforcement Learning (RL) algorithm to synthesise policies for an unknown Markov Decision Process (MDP), such that a linear time property is satisfied. The given temporal property is converted into a Limit Deterministic Buchi Automaton (LDBA) and a robust reward function is defined over the state-action pairs of the MDP according to the resulting LDBA. With this reward function, the policy synthesis procedure is "constrained" by the given specification. These constraints guide the MDP exploration so as to minimize the solution time by only considering the portion of the MDP that is relevant to satisfaction of the LTL property. This improves performance and scalability of the proposed method by avoiding an exhaustive update over the whole state space while the efficiency of standard methods such as dynamic programming is hindered by excessive memory requirements, caused by the need to store a full-model in memory. Additionally, we show that the RL procedure sets up a local value iteration method to efficiently calculate the maximum probability of satisfying the given property, at any given state of the MDP. We prove that our algorithm is guaranteed to find a policy whose traces probabilistically satisfy the LTL property if such a policy exists, and additionally we show that our method produces reasonable control policies even when the LTL property cannot be satisfied. The performance of the algorithm is evaluated via a set of numerical examples. We observe an improvement of one order of magnitude in the number of iterations required for the synthesis compared to existing approaches.},
  archiveprefix = {arXiv},
  eprint        = {1801.08099},
  file          = {:http\://arxiv.org/pdf/1801.08099v8:PDF},
  groups        = {Model Checking},
  keywords      = {cs.LG, cs.LO},
  primaryclass  = {cs.LG},
}

@InCollection{rawson2019neurally,
  author    = {Michael Rawson and Giles Reger},
  booktitle = {Frontiers of Combining Systems},
  publisher = {Springer International Publishing},
  title     = {A Neurally-Guided, Parallel Theorem Prover},
  year      = {2019},
  pages     = {40--56},
  doi       = {10.1007/978-3-030-29007-8_3},
  groups    = {Automated Theorem Proving},
}

@InCollection{selsam2019guiding,
  author    = {Daniel Selsam and Nikolaj Bj{\o}rner},
  booktitle = {Lecture Notes in Computer Science},
  publisher = {Springer International Publishing},
  title     = {Guiding High-Performance {SAT} Solvers with Unsat-Core Predictions},
  year      = {2019},
  pages     = {336--353},
  doi       = {10.1007/978-3-030-24258-9_24},
  groups    = {Automated Theorem Proving},
}

@Article{blanchette2016learning,
  author    = {Jasmin Christian Blanchette and David Greenaway and Cezary Kaliszyk and Daniel K√ºhlwein and Josef Urban},
  journal   = {Journal of Automated Reasoning},
  title     = {A Learning-Based Fact Selector for Isabelle/{HOL}},
  year      = {2016},
  month     = {feb},
  number    = {3},
  pages     = {219--244},
  volume    = {57},
  doi       = {10.1007/s10817-016-9362-8},
  groups    = {Automated Theorem Proving},
  publisher = {Springer Science and Business Media {LLC}},
}

@InCollection{liang2016learning,
  author    = {Jia Hui Liang and Vijay Ganesh and Pascal Poupart and Krzysztof Czarnecki},
  booktitle = {Theory and Applications of Satisfiability Testing {\textendash} {SAT} 2016},
  publisher = {Springer International Publishing},
  title     = {Learning Rate Based Branching Heuristic for {SAT} Solvers},
  year      = {2016},
  pages     = {123--140},
  doi       = {10.1007/978-3-319-40970-2_9},
  groups    = {Automated Theorem Proving},
}

@InCollection{faerber2015random,
  author    = {Michael F√§rber and Cezary Kaliszyk},
  booktitle = {Frontiers of Combining Systems},
  publisher = {Springer International Publishing},
  title     = {Random Forests for Premise Selection},
  year      = {2015},
  pages     = {325--340},
  doi       = {10.1007/978-3-319-24246-0_20},
  groups    = {Automated Theorem Proving},
}

@Article{kaliszyk2015learning,
  author    = {Cezary Kaliszyk and Josef Urban},
  journal   = {Journal of Symbolic Computation},
  title     = {Learning-assisted theorem proving with millions of lemmas},
  year      = {2015},
  month     = {jul},
  pages     = {109--128},
  volume    = {69},
  doi       = {10.1016/j.jsc.2014.09.032},
  groups    = {Automated Theorem Proving},
  publisher = {Elsevier {BV}},
}

@InCollection{kuehlwein2012overview,
  author    = {Daniel K√ºhlwein and Twan van Laarhoven and Evgeni Tsivtsivadze and Josef Urban and Tom Heskes},
  booktitle = {Automated Reasoning},
  publisher = {Springer Berlin Heidelberg},
  title     = {Overview and Evaluation of Premise Selection Techniques for Large Theory Mathematics},
  year      = {2012},
  pages     = {378--392},
  doi       = {10.1007/978-3-642-31365-3_30},
  groups    = {Automated Theorem Proving, Surveys},
}

@Article{selsam2018learning,
  author        = {Daniel Selsam and Matthew Lamm and Benedikt B√ºnz and Percy Liang and Leonardo de Moura and David L. Dill},
  title         = {Learning a SAT Solver from Single-Bit Supervision},
  year          = {2018},
  month         = feb,
  abstract      = {We present NeuroSAT, a message passing neural network that learns to solve SAT problems after only being trained as a classifier to predict satisfiability. Although it is not competitive with state-of-the-art SAT solvers, NeuroSAT can solve problems that are substantially larger and more difficult than it ever saw during training by simply running for more iterations. Moreover, NeuroSAT generalizes to novel distributions; after training only on random SAT problems, at test time it can solve SAT problems encoding graph coloring, clique detection, dominating set, and vertex cover problems, all on a range of distributions over small random graphs.},
  archiveprefix = {arXiv},
  eprint        = {1802.03685},
  file          = {:http\://arxiv.org/pdf/1802.03685v4:PDF},
  groups        = {Automated Theorem Proving},
  keywords      = {cs.AI, cs.LG, cs.LO},
  primaryclass  = {cs.AI},
}

@Article{lederman2018learning,
  author        = {Gil Lederman and Markus N. Rabe and Edward A. Lee and Sanjit A. Seshia},
  title         = {Learning Heuristics for Quantified Boolean Formulas through Deep Reinforcement Learning},
  year          = {2018},
  month         = jul,
  abstract      = {We demonstrate how to learn efficient heuristics for automated reasoning algorithms for quantified Boolean formulas through deep reinforcement learning. We focus on a backtracking search algorithm, which can already solve formulas of impressive size - up to hundreds of thousands of variables. The main challenge is to find a representation of these formulas that lends itself to making predictions in a scalable way. For a family of challenging problems, we learned a heuristic that solves significantly more formulas compared to the existing handwritten heuristics.},
  archiveprefix = {arXiv},
  eprint        = {1807.08058},
  file          = {:http\://arxiv.org/pdf/1807.08058v3:PDF},
  groups        = {Automated Theorem Proving},
  keywords      = {cs.LO, cs.AI, cs.LG},
  primaryclass  = {cs.LO},
}

@InCollection{urban2013theorem,
  author    = {Josef Urban and Ji{\v{r}}{\'{\i}} Vysko{\v{c}}il},
  booktitle = {Automated Reasoning and Mathematics},
  publisher = {Springer Berlin Heidelberg},
  title     = {Theorem Proving in Large Formal Mathematics as an Emerging {AI} Field},
  year      = {2013},
  pages     = {240--257},
  doi       = {10.1007/978-3-642-36675-8_13},
  groups    = {Automated Theorem Proving},
}

@Article{kaliszyk2013stronger,
  author    = {Kaliszyk, Cezary and Urban, Josef},
  title     = {Stronger automation for {Flyspeck} by feature weighting and strategy evolution},
  year      = {2013},
  groups    = {Automated Theorem Proving},
  publisher = {[Sl]: EasyChair},
  url       = {https://hdl.handle.net/2066/119984},
}

@Unpublished{goldman2015employing,
  author = {Goldman, Robert P and Boldt, Michael W and Musliner, David J},
  note   = {Available at \url{https://www.sift.net/publications/employing-ai-techniques-probabilistic-model-checking}},
  title  = {Employing AI Techniques in Probabilistic Model Checking Position Paper},
  year   = {2015},
  groups = {Automated Theorem Proving, Model Checking},
  url    = {https://www.sift.net/publications/employing-ai-techniques-probabilistic-model-checking},
}

@InCollection{blanchette2014survey,
  author    = {Blanchette, Jasmin Christian and K{\"u}hlwein, Daniel},
  booktitle = {Infinity, Computability, and Metamathematics: Festschrift Celebrating the 60th Birthdays of Peter Koepke and Philip Welch},
  publisher = {Tributes, College Publications},
  title     = {A Survey of Axiom Selection as a Machine Learning Problem},
  year      = {2014},
  eprint    = {https://www21.in.tum.de/~blanchet/axiom_sel.pdf},
  groups    = {Automated Theorem Proving, Surveys},
}

@InProceedings{NEURIPS2018_55acf853,
  author    = {Kaliszyk, Cezary and Urban, Josef and Michalewski, Henryk and Ol\v{s}\'{a}k, Miroslav},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {Reinforcement Learning of Theorem Proving},
  year      = {2018},
  editor    = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
  publisher = {Curran Associates, Inc.},
  volume    = {31},
  eprint    = {https://proceedings.neurips.cc/paper/2018/file/55acf8539596d25624059980986aaa78-Paper.pdf},
  groups    = {Automated Theorem Proving},
}

@InProceedings{blanchette:hal-02381430,
  author    = {Blanchette, Jasmin Christian and Ouraoui, Daniel El and Fontaine, Pascal and Kaliszyk, Cezary},
  booktitle = {{AITP 2019 - 4th Conference on Artificial Intelligence and Theorem Proving}},
  title     = {{Machine Learning for Instance Selection in SMT Solving}},
  year      = {2019},
  address   = {Obergurgl, Austria},
  month     = Apr,
  eprint    = {https://hal.archives-ouvertes.fr/hal-02381430/document},
  groups    = {Automated Theorem Proving},
  pdf       = {https://hal.archives-ouvertes.fr/hal-02381430/file/paper.pdf},
  url       = {https://hal.archives-ouvertes.fr/hal-02381430},
}

@PhdThesis{Lederman:EECS-2021-135,
  author = {Lederman, Gil},
  school = {EECS Department, University of California, Berkeley},
  title  = {Neural Guidance in Constraint Solvers},
  year   = {2021},
  month  = {May},
  groups = {Automated Theorem Proving},
  number = {UCB/EECS-2021-135},
  url    = {http://www2.eecs.berkeley.edu/Pubs/TechRpts/2021/EECS-2021-135.html},
}

@MastersThesis{Bavishi:EECS-2019-82,
  author = {Bavishi, Rohan},
  school = {EECS Department, University of California, Berkeley},
  title  = {Neural-Backed Generators for Program Synthesis},
  year   = {2019},
  month  = {May},
  groups = {Synthesis and Repair},
  number = {UCB/EECS-2019-82},
  url    = {http://www2.eecs.berkeley.edu/Pubs/TechRpts/2019/EECS-2019-82.html},
}

@InCollection{fedyukovich2019quantified,
  author    = {Grigory Fedyukovich and Sumanth Prabhu and Kumar Madhukar and Aarti Gupta},
  booktitle = {Computer Aided Verification},
  publisher = {Springer International Publishing},
  title     = {Quantified Invariants via Syntax-Guided Synthesis},
  year      = {2019},
  pages     = {259--277},
  doi       = {10.1007/978-3-030-25540-4_14},
  groups    = {Invariant Learning},
}

@InCollection{zhang2020synthesizing,
  author    = {Hongce Zhang and Weikun Yang and Grigory Fedyukovich and Aarti Gupta and Sharad Malik},
  booktitle = {Lecture Notes in Computer Science},
  publisher = {Springer International Publishing},
  title     = {Synthesizing Environment Invariants for Modular Hardware Verification},
  year      = {2020},
  pages     = {202--225},
  doi       = {10.1007/978-3-030-39322-9_10},
  groups    = {Invariant Learning},
}

@InProceedings{mordvinov2019property,
  author    = {Dmitry Mordvinov and Grigory Fedyukovich},
  booktitle = {2019 Formal Methods in Computer Aided Design ({FMCAD})},
  title     = {Property Directed Inference of Relational Invariants},
  year      = {2019},
  month     = {oct},
  publisher = {{IEEE}},
  doi       = {10.23919/fmcad.2019.8894274},
  groups    = {Invariant Learning},
}

@InCollection{fedyukovich2018accelerating,
  author    = {Grigory Fedyukovich and Rastislav Bod{\'{\i}}k},
  booktitle = {Tools and Algorithms for the Construction and Analysis of Systems},
  publisher = {Springer International Publishing},
  title     = {Accelerating Syntax-Guided Invariant Synthesis},
  year      = {2018},
  pages     = {251--269},
  doi       = {10.1007/978-3-319-89960-2_14},
  groups    = {Invariant Learning},
}

@InProceedings{fedyukovich2018solving,
  author    = {Grigory Fedyukovich and Sumanth Prabhu and Kumar Madhukar and Aarti Gupta},
  booktitle = {2018 Formal Methods in Computer Aided Design ({FMCAD})},
  title     = {Solving Constrained Horn Clauses Using Syntax and Data},
  year      = {2018},
  month     = {oct},
  publisher = {{IEEE}},
  doi       = {10.23919/fmcad.2018.8603011},
  groups    = {Invariant Learning},
}

@InCollection{gurfinkel2018quantifiers,
  author    = {Arie Gurfinkel and Sharon Shoham and Yakir Vizel},
  booktitle = {Automated Technology for Verification and Analysis},
  publisher = {Springer International Publishing},
  title     = {Quantifiers on Demand},
  year      = {2018},
  pages     = {248--266},
  doi       = {10.1007/978-3-030-01090-4_15},
  groups    = {Invariant Learning},
}

@InCollection{prabhu2018efficiently,
  author    = {Sumanth Prabhu and Kumar Madhukar and R. Venkatesh},
  booktitle = {Static Analysis},
  publisher = {Springer International Publishing},
  title     = {Efficiently Learning Safety Proofs from Appearance as well as Behaviours},
  year      = {2018},
  pages     = {326--343},
  doi       = {10.1007/978-3-319-99725-4_20},
  groups    = {Invariant Learning},
}

@InCollection{vizel2017ic3,
  author    = {Yakir Vizel and Arie Gurfinkel and Sharon Shoham and Sharad Malik},
  booktitle = {Lecture Notes in Computer Science},
  publisher = {Springer International Publishing},
  title     = {{IC}3 - Flipping the E in {ICE}},
  year      = {2017},
  pages     = {521--538},
  doi       = {10.1007/978-3-319-52234-0_28},
  groups    = {Invariant Learning},
}

@Article{garg2016learning,
  author    = {Pranav Garg and Daniel Neider and P. Madhusudan and Dan Roth},
  journal   = {{ACM} {SIGPLAN} Notices},
  title     = {Learning invariants using decision trees and implication counterexamples},
  year      = {2016},
  month     = {apr},
  number    = {1},
  pages     = {499--512},
  volume    = {51},
  doi       = {10.1145/2914770.2837664},
  groups    = {Invariant Learning},
  publisher = {Association for Computing Machinery ({ACM})},
}

@InCollection{loeding2016abstract,
  author    = {Christof L√∂ding and P. Madhusudan and Daniel Neider},
  booktitle = {Tools and Algorithms for the Construction and Analysis of Systems},
  publisher = {Springer Berlin Heidelberg},
  title     = {Abstract Learning Frameworks for Synthesis},
  year      = {2016},
  pages     = {167--185},
  doi       = {10.1007/978-3-662-49674-9_10},
  groups    = {Invariant Learning},
}

@InCollection{garg2014icearobustframeworkforlearninginvariants,
  author    = {Pranav Garg and Christof L√∂ding and P. Madhusudan and Daniel Neider},
  booktitle = {Computer Aided Verification},
  publisher = {Springer International Publishing},
  title     = {{ICE}:~A~Robust~Framework~for~Learning~Invariants},
  year      = {2014},
  pages     = {69--87},
  doi       = {10.1007/978-3-319-08867-9_5},
  groups    = {Invariant Learning},
}

@InCollection{garg2013learninguniversallyquantifiedinvariants,
  author    = {Pranav Garg and Christof L√∂ding and P. Madhusudan and Daniel Neider},
  booktitle = {Computer Aided Verification},
  publisher = {Springer Berlin Heidelberg},
  title     = {Learning~Universally~Quantified~Invariants of Linear~Data~Structures},
  year      = {2013},
  pages     = {813--829},
  doi       = {10.1007/978-3-642-39799-8_57},
  groups    = {Invariant Learning},
}

@InCollection{sharma2013data,
  author    = {Rahul Sharma and Saurabh Gupta and Bharath Hariharan and Alex Aiken and Percy Liang and Aditya V. Nori},
  booktitle = {Programming Languages and Systems},
  publisher = {Springer Berlin Heidelberg},
  title     = {A Data Driven Approach for Algebraic Loop Invariants},
  year      = {2013},
  pages     = {574--592},
  doi       = {10.1007/978-3-642-37036-6_31},
  groups    = {Invariant Learning},
}

@InProceedings{NIPS2016_f197002b,
  author    = {Irving, Geoffrey and Szegedy, Christian and Alemi, Alexander A and Een, Niklas and Chollet, Francois and Urban, Josef},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {DeepMath - Deep Sequence Models for Premise Selection},
  year      = {2016},
  editor    = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
  publisher = {Curran Associates, Inc.},
  volume    = {29},
  groups    = {Invariant Learning},
  url       = {https://proceedings.neurips.cc/paper/2016/file/f197002b9a0853eca5e046d9ca4663d5-Paper.pdf},
}

@Article{shafiq2020machine,
  author        = {Saad Shafiq and Atif Mashkoor and Christoph Mayr-Dorn and Alexander Egyed},
  title         = {Machine Learning for Software Engineering: A Systematic Mapping},
  year          = {2020},
  month         = may,
  abstract      = {Context: The software development industry is rapidly adopting machine learning for transitioning modern day software systems towards highly intelligent and self-learning systems. However, the full potential of machine learning for improving the software engineering life cycle itself is yet to be discovered, i.e., up to what extent machine learning can help reducing the effort/complexity of software engineering and improving the quality of resulting software systems. To date, no comprehensive study exists that explores the current state-of-the-art on the adoption of machine learning across software engineering life cycle stages. Objective: This article addresses the aforementioned problem and aims to present a state-of-the-art on the growing number of uses of machine learning in software engineering. Method: We conduct a systematic mapping study on applications of machine learning to software engineering following the standard guidelines and principles of empirical software engineering. Results: This study introduces a machine learning for software engineering (MLSE) taxonomy classifying the state-of-the-art machine learning techniques according to their applicability to various software engineering life cycle stages. Overall, 227 articles were rigorously selected and analyzed as a result of this study. Conclusion: From the selected articles, we explore a variety of aspects that should be helpful to academics and practitioners alike in understanding the potential of adopting machine learning techniques during software engineering projects.},
  archiveprefix = {arXiv},
  doi           = {10.1109/ACCESS.2021.3119746},
  eprint        = {2005.13299},
  file          = {:http\://arxiv.org/pdf/2005.13299v1:PDF},
  groups        = {ML for General Software Development, Surveys},
  keywords      = {cs.SE, cs.LG},
  primaryclass  = {cs.SE},
}

@Article{bundy2012ai,
  author    = {Bundy, Alan and Hutter, Dieter and Jones, Cliff B. and Moore, J Strother},
  title     = {AI meets Formal Software Development (Dagstuhl Seminar 12271)},
  year      = {2012},
  doi       = {10.4230/DAGREP.2.7.1},
  groups    = {AI for Formal Software Development},
  keywords  = {Computer Science, 000 Computer science, knowledge, general works},
  language  = {en},
  publisher = {Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik GmbH, Wadern/Saarbruecken, Germany},
}

@InCollection{bak2020improved,
  author    = {Stanley Bak and Hoang-Dung Tran and Kerianne Hobbs and Taylor T. Johnson},
  booktitle = {Computer Aided Verification},
  publisher = {Springer International Publishing},
  title     = {Improved Geometric Path Enumeration for Verifying {ReLU} Neural Networks},
  year      = {2020},
  pages     = {66--96},
  doi       = {10.1007/978-3-030-53288-8_4},
  groups    = {Neural Networks},
}

@Article{tran2020nnv,
  author        = {Hoang-Dung Tran and Xiaodong Yang and Diego Manzanas Lopez and Patrick Musau and Luan Viet Nguyen and Weiming Xiang and Stanley Bak and Taylor T. Johnson},
  title         = {NNV: The Neural Network Verification Tool for Deep Neural Networks and Learning-Enabled Cyber-Physical Systems},
  year          = {2020},
  month         = apr,
  abstract      = {This paper presents the Neural Network Verification (NNV) software tool, a set-based verification framework for deep neural networks (DNNs) and learning-enabled cyber-physical systems (CPS). The crux of NNV is a collection of reachability algorithms that make use of a variety of set representations, such as polyhedra, star sets, zonotopes, and abstract-domain representations. NNV supports both exact (sound and complete) and over-approximate (sound) reachability algorithms for verifying safety and robustness properties of feed-forward neural networks (FFNNs) with various activation functions. For learning-enabled CPS, such as closed-loop control systems incorporating neural networks, NNV provides exact and over-approximate reachability analysis schemes for linear plant models and FFNN controllers with piecewise-linear activation functions, such as ReLUs. For similar neural network control systems (NNCS) that instead have nonlinear plant models, NNV supports over-approximate analysis by combining the star set analysis used for FFNN controllers with zonotope-based analysis for nonlinear plant dynamics building on CORA. We evaluate NNV using two real-world case studies: the first is safety verification of ACAS Xu networks and the second deals with the safety verification of a deep learning-based adaptive cruise control system.},
  archiveprefix = {arXiv},
  eprint        = {2004.05519},
  file          = {:http\://arxiv.org/pdf/2004.05519v1:PDF},
  groups        = {Neural Networks},
  keywords      = {eess.SY, cs.LG, cs.SY},
  primaryclass  = {eess.SY},
}

@Article{tran2020verification,
  author        = {Hoang-Dung Tran and Stanley Bak and Weiming Xiang and Taylor T. Johnson},
  title         = {Verification of Deep Convolutional Neural Networks Using ImageStars},
  year          = {2020},
  month         = apr,
  abstract      = {Convolutional Neural Networks (CNN) have redefined the state-of-the-art in many real-world applications, such as facial recognition, image classification, human pose estimation, and semantic segmentation. Despite their success, CNNs are vulnerable to adversarial attacks, where slight changes to their inputs may lead to sharp changes in their output in even well-trained networks. Set-based analysis methods can detect or prove the absence of bounded adversarial attacks, which can then be used to evaluate the effectiveness of neural network training methodology. Unfortunately, existing verification approaches have limited scalability in terms of the size of networks that can be analyzed. In this paper, we describe a set-based framework that successfully deals with real-world CNNs, such as VGG16 and VGG19, that have high accuracy on ImageNet. Our approach is based on a new set representation called the ImageStar, which enables efficient exact and over-approximative analysis of CNNs. ImageStars perform efficient set-based analysis by combining operations on concrete images with linear programming (LP). Our approach is implemented in a tool called NNV, and can verify the robustness of VGG networks with respect to a small set of input states, derived from adversarial attacks, such as the DeepFool attack. The experimental results show that our approach is less conservative and faster than existing zonotope methods, such as those used in DeepZ, and the polytope method used in DeepPoly.},
  archiveprefix = {arXiv},
  eprint        = {2004.05511},
  file          = {:http\://arxiv.org/pdf/2004.05511v2:PDF},
  groups        = {Neural Networks},
  keywords      = {cs.LG, cs.CV},
  primaryclass  = {cs.LG},
}

@Article{wu2020game,
  author    = {Min Wu and Matthew Wicker and Wenjie Ruan and Xiaowei Huang and Marta Kwiatkowska},
  journal   = {Theoretical Computer Science},
  title     = {A game-based approximate verification of deep neural networks with provable guarantees},
  year      = {2020},
  month     = {feb},
  pages     = {298--329},
  volume    = {807},
  doi       = {10.1016/j.tcs.2019.05.046},
  groups    = {Neural Networks},
  publisher = {Elsevier {BV}},
}

@Article{dreossi2019formalization,
  author        = {Tommaso Dreossi and Shromona Ghosh and Alberto Sangiovanni-Vincentelli and Sanjit A. Seshia},
  title         = {A Formalization of Robustness for Deep Neural Networks},
  year          = {2019},
  month         = mar,
  abstract      = {Deep neural networks have been shown to lack robustness to small input perturbations. The process of generating the perturbations that expose the lack of robustness of neural networks is known as adversarial input generation. This process depends on the goals and capabilities of the adversary, In this paper, we propose a unifying formalization of the adversarial input generation process from a formal methods perspective. We provide a definition of robustness that is general enough to capture different formulations. The expressiveness of our formalization is shown by modeling and comparing a variety of adversarial attack techniques.},
  archiveprefix = {arXiv},
  eprint        = {1903.10033},
  file          = {:http\://arxiv.org/pdf/1903.10033v1:PDF},
  groups        = {Neural Networks},
  keywords      = {cs.LG},
  primaryclass  = {cs.LG},
}

@Article{huang2018survey,
  author        = {Xiaowei Huang and Daniel Kroening and Wenjie Ruan and James Sharp and Youcheng Sun and Emese Thamo and Min Wu and Xinping Yi},
  title         = {A Survey of Safety and Trustworthiness of Deep Neural Networks: Verification, Testing, Adversarial Attack and Defence, and Interpretability},
  year          = {2018},
  month         = dec,
  abstract      = {In the past few years, significant progress has been made on deep neural networks (DNNs) in achieving human-level performance on several long-standing tasks. With the broader deployment of DNNs on various applications, the concerns over their safety and trustworthiness have been raised in public, especially after the widely reported fatal incidents involving self-driving cars. Research to address these concerns is particularly active, with a significant number of papers released in the past few years. This survey paper conducts a review of the current research effort into making DNNs safe and trustworthy, by focusing on four aspects: verification, testing, adversarial attack and defence, and interpretability. In total, we survey 202 papers, most of which were published after 2017.},
  archiveprefix = {arXiv},
  eprint        = {1812.08342},
  file          = {:http\://arxiv.org/pdf/1812.08342v5:PDF},
  groups        = {Neural Networks, Surveys},
  keywords      = {cs.LG, cs.AI, I.2; F.3.1},
  primaryclass  = {cs.LG},
}

@InCollection{katz2019marabou,
  author    = {Guy Katz and Derek A. Huang and Duligur Ibeling and Kyle Julian and Christopher Lazarus and Rachel Lim and Parth Shah and Shantanu Thakoor and Haoze Wu and Aleksandar Zelji{\'{c}} and David L. Dill and Mykel J. Kochenderfer and Clark Barrett},
  booktitle = {Computer Aided Verification},
  publisher = {Springer International Publishing},
  title     = {The Marabou Framework for Verification and Analysis of Deep Neural Networks},
  year      = {2019},
  pages     = {443--452},
  doi       = {10.1007/978-3-030-25540-4_26},
  groups    = {Neural Networks},
}

@Article{liu2019algorithms,
  author        = {Changliu Liu and Tomer Arnon and Christopher Lazarus and Christopher Strong and Clark Barrett and Mykel J. Kochenderfer},
  title         = {Algorithms for Verifying Deep Neural Networks},
  year          = {2019},
  month         = mar,
  abstract      = {Deep neural networks are widely used for nonlinear function approximation with applications ranging from computer vision to control. Although these networks involve the composition of simple arithmetic operations, it can be very challenging to verify whether a particular network satisfies certain input-output properties. This article surveys methods that have emerged recently for soundly verifying such properties. These methods borrow insights from reachability analysis, optimization, and search. We discuss fundamental differences and connections between existing algorithms. In addition, we provide pedagogical implementations of existing methods and compare them on a set of benchmark problems.},
  archiveprefix = {arXiv},
  eprint        = {1903.06758},
  file          = {:http\://arxiv.org/pdf/1903.06758v2:PDF},
  groups        = {Neural Networks},
  keywords      = {cs.LG, stat.ML},
  primaryclass  = {cs.LG},
}

@InProceedings{217595,
  author    = {Shiqi Wang and Kexin Pei and Justin Whitehouse and Junfeng Yang and Suman Jana},
  booktitle = {27th USENIX Security Symposium (USENIX Security 18)},
  title     = {Formal Security Analysis of Neural Networks using Symbolic Intervals},
  year      = {2018},
  address   = {Baltimore, MD},
  month     = aug,
  pages     = {1599--1614},
  publisher = {USENIX Association},
  groups    = {Neural Networks},
  isbn      = {978-1-939133-04-5},
  url       = {https://www.usenix.org/conference/usenixsecurity18/presentation/wang-shiqi},
}

@Article{pei2019bringing,
  author    = {Kexin Pei and Shiqi Wang and Yuchi Tian and Justin Whitehouse and Carl Vondrick and Yinzhi Cao and Baishakhi Ray and Suman Jana and Junfeng Yang},
  journal   = {{ACM} {SIGOPS} Operating Systems Review},
  title     = {Bringing Engineering Rigor to Deep Learning},
  year      = {2019},
  month     = {jul},
  number    = {1},
  pages     = {59--67},
  volume    = {53},
  doi       = {10.1145/3352020.3352030},
  groups    = {Neural Networks},
  publisher = {Association for Computing Machinery ({ACM})},
}

@InCollection{tran2019star,
  author    = {Hoang-Dung Tran and Diago Manzanas Lopez and Patrick Musau and Xiaodong Yang and Luan Viet Nguyen and Weiming Xiang and Taylor T. Johnson},
  booktitle = {Lecture Notes in Computer Science},
  publisher = {Springer International Publishing},
  title     = {Star-Based Reachability Analysis of Deep Neural Networks},
  year      = {2019},
  pages     = {670--686},
  doi       = {10.1007/978-3-030-30942-8_39},
  groups    = {Neural Networks},
}

@InCollection{dreossi2018semantic,
  author    = {Tommaso Dreossi and Somesh Jha and Sanjit A. Seshia},
  booktitle = {Computer Aided Verification},
  publisher = {Springer International Publishing},
  title     = {Semantic Adversarial Deep Learning},
  year      = {2018},
  pages     = {3--26},
  doi       = {10.1007/978-3-319-96145-3_1},
  groups    = {Neural Networks},
}

@InProceedings{gehr2018ai2,
  author    = {Timon Gehr and Matthew Mirman and Dana Drachsler-Cohen and Petar Tsankov and Swarat Chaudhuri and Martin Vechev},
  booktitle = {2018 {IEEE} Symposium on Security and Privacy ({SP})},
  title     = {{AI}2: Safety and Robustness Certification of Neural Networks with Abstract Interpretation},
  year      = {2018},
  month     = {may},
  publisher = {{IEEE}},
  doi       = {10.1109/sp.2018.00058},
  groups    = {Neural Networks},
}

@Article{ruan2018reachability,
  author        = {Wenjie Ruan and Xiaowei Huang and Marta Kwiatkowska},
  title         = {Reachability Analysis of Deep Neural Networks with Provable Guarantees},
  year          = {2018},
  month         = may,
  abstract      = {Verifying correctness of deep neural networks (DNNs) is challenging. We study a generic reachability problem for feed-forward DNNs which, for a given set of inputs to the network and a Lipschitz-continuous function over its outputs, computes the lower and upper bound on the function values. Because the network and the function are Lipschitz continuous, all values in the interval between the lower and upper bound are reachable. We show how to obtain the safety verification problem, the output range analysis problem and a robustness measure by instantiating the reachability problem. We present a novel algorithm based on adaptive nested optimisation to solve the reachability problem. The technique has been implemented and evaluated on a range of DNNs, demonstrating its efficiency, scalability and ability to handle a broader class of networks than state-of-the-art verification approaches.},
  archiveprefix = {arXiv},
  eprint        = {1805.02242},
  file          = {:http\://arxiv.org/pdf/1805.02242v1:PDF},
  groups        = {Neural Networks},
  keywords      = {cs.LG, cs.CV, stat.ML},
  primaryclass  = {cs.LG},
}

@InCollection{seshia2018formal,
  author    = {Sanjit A. Seshia and Ankush Desai and Tommaso Dreossi and Daniel J. Fremont and Shromona Ghosh and Edward Kim and Sumukh Shivakumar and Marcell Vazquez-Chanlatte and Xiangyu Yue},
  booktitle = {Automated Technology for Verification and Analysis},
  publisher = {Springer International Publishing},
  title     = {Formal Specification for Deep Neural Networks},
  year      = {2018},
  pages     = {20--34},
  doi       = {10.1007/978-3-030-01090-4_2},
  groups    = {Neural Networks},
}

@InProceedings{pmlr-v80-wong18a,
  author    = {Wong, Eric and Kolter, Zico},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning},
  title     = {Provable Defenses against Adversarial Examples via the Convex Outer Adversarial Polytope},
  year      = {2018},
  editor    = {Dy, Jennifer and Krause, Andreas},
  month     = {10--15 Jul},
  pages     = {5286--5295},
  publisher = {PMLR},
  series    = {Proceedings of Machine Learning Research},
  volume    = {80},
  groups    = {Neural Networks},
  pdf       = {http://proceedings.mlr.press/v80/wong18a/wong18a.pdf},
  url       = {https://proceedings.mlr.press/v80/wong18a.html},
}

@Article{xiang2018specification,
  author        = {Weiming Xiang and Hoang-Dung Tran and Taylor T. Johnson},
  title         = {Specification-Guided Safety Verification for Feedforward Neural Networks},
  year          = {2018},
  month         = dec,
  abstract      = {This paper presents a specification-guided safety verification method for feedforward neural networks with general activation functions. As such feedforward networks are memoryless, they can be abstractly represented as mathematical functions, and the reachability analysis of the neural network amounts to interval analysis problems. In the framework of interval analysis, a computationally efficient formula which can quickly compute the output interval sets of a neural network is developed. Then, a specification-guided reachability algorithm is developed. Specifically, the bisection process in the verification algorithm is completely guided by a given safety specification. Due to the employment of the safety specification, unnecessary computations are avoided and thus the computational cost can be reduced significantly. Experiments show that the proposed method enjoys much more efficiency in safety verification with significantly less computational cost.},
  archiveprefix = {arXiv},
  eprint        = {1812.06161},
  file          = {:http\://arxiv.org/pdf/1812.06161v1:PDF},
  groups        = {Neural Networks},
  keywords      = {cs.LG, cs.AI},
  primaryclass  = {cs.LG},
}

@Article{xiang2018verification,
  author        = {Weiming Xiang and Patrick Musau and Ayana A. Wild and Diego Manzanas Lopez and Nathaniel Hamilton and Xiaodong Yang and Joel Rosenfeld and Taylor T. Johnson},
  title         = {Verification for Machine Learning, Autonomy, and Neural Networks Survey},
  year          = {2018},
  month         = oct,
  abstract      = {This survey presents an overview of verification techniques for autonomous systems, with a focus on safety-critical autonomous cyber-physical systems (CPS) and subcomponents thereof. Autonomy in CPS is enabling by recent advances in artificial intelligence (AI) and machine learning (ML) through approaches such as deep neural networks (DNNs), embedded in so-called learning enabled components (LECs) that accomplish tasks from classification to control. Recently, the formal methods and formal verification community has developed methods to characterize behaviors in these LECs with eventual goals of formally verifying specifications for LECs, and this article presents a survey of many of these recent approaches.},
  archiveprefix = {arXiv},
  eprint        = {1810.01989},
  file          = {:http\://arxiv.org/pdf/1810.01989v1:PDF},
  groups        = {Neural Networks, Surveys},
  keywords      = {cs.AI, cs.LG},
  primaryclass  = {cs.AI},
}

@Article{dutta2017output,
  author        = {Souradeep Dutta and Susmit Jha and Sriram Sanakaranarayanan and Ashish Tiwari},
  title         = {Output Range Analysis for Deep Neural Networks},
  year          = {2017},
  month         = sep,
  abstract      = {Deep neural networks (NN) are extensively used for machine learning tasks such as image classification, perception and control of autonomous systems. Increasingly, these deep NNs are also been deployed in high-assurance applications. Thus, there is a pressing need for developing techniques to verify neural networks to check whether certain user-expected properties are satisfied. In this paper, we study a specific verification problem of computing a guaranteed range for the output of a deep neural network given a set of inputs represented as a convex polyhedron. Range estimation is a key primitive for verifying deep NNs. We present an efficient range estimation algorithm that uses a combination of local search and linear programming problems to efficiently find the maximum and minimum values taken by the outputs of the NN over the given input set. In contrast to recently proposed "monolithic" optimization approaches, we use local gradient descent to repeatedly find and eliminate local minima of the function. The final global optimum is certified using a mixed integer programming instance. We implement our approach and compare it with Reluplex, a recently proposed solver for deep neural networks. We demonstrate the effectiveness of the proposed approach for verification of NNs used in automated control as well as those used in classification.},
  archiveprefix = {arXiv},
  eprint        = {1709.09130},
  file          = {:http\://arxiv.org/pdf/1709.09130v1:PDF},
  groups        = {Neural Networks},
  keywords      = {cs.LG, stat.ML},
  primaryclass  = {cs.LG},
}

@InCollection{huang2017safety,
  author    = {Xiaowei Huang and Marta Kwiatkowska and Sen Wang and Min Wu},
  booktitle = {Computer Aided Verification},
  publisher = {Springer International Publishing},
  title     = {Safety Verification of Deep Neural Networks},
  year      = {2017},
  pages     = {3--29},
  doi       = {10.1007/978-3-319-63387-9_1},
  groups    = {Neural Networks},
}

@InCollection{katz2017reluplex,
  author    = {Guy Katz and Clark Barrett and David L. Dill and Kyle Julian and Mykel J. Kochenderfer},
  booktitle = {Computer Aided Verification},
  publisher = {Springer International Publishing},
  title     = {Reluplex: An Efficient {SMT} Solver for Verifying Deep Neural Networks},
  year      = {2017},
  pages     = {97--117},
  doi       = {10.1007/978-3-319-63387-9_5},
  groups    = {Neural Networks},
}

@Article{narodytska2017verifying,
  author        = {Nina Narodytska and Shiva Prasad Kasiviswanathan and Leonid Ryzhyk and Mooly Sagiv and Toby Walsh},
  title         = {Verifying Properties of Binarized Deep Neural Networks},
  year          = {2017},
  month         = sep,
  abstract      = {Understanding properties of deep neural networks is an important challenge in deep learning. In this paper, we take a step in this direction by proposing a rigorous way of verifying properties of a popular class of neural networks, Binarized Neural Networks, using the well-developed means of Boolean satisfiability. Our main contribution is a construction that creates a representation of a binarized neural network as a Boolean formula. Our encoding is the first exact Boolean representation of a deep neural network. Using this encoding, we leverage the power of modern SAT solvers along with a proposed counterexample-guided search procedure to verify various properties of these networks. A particular focus will be on the critical property of robustness to adversarial perturbations. For this property, our experimental results demonstrate that our approach scales to medium-size deep neural networks used in image classification tasks. To the best of our knowledge, this is the first work on verifying properties of deep neural networks using an exact Boolean encoding of the network.},
  archiveprefix = {arXiv},
  eprint        = {1709.06662},
  file          = {:http\://arxiv.org/pdf/1709.06662v2:PDF},
  groups        = {Neural Networks},
  keywords      = {stat.ML, cs.AI, cs.CR, cs.LG},
  primaryclass  = {stat.ML},
}

@Article{pei2017deepxplore,
  author        = {Kexin Pei and Yinzhi Cao and Junfeng Yang and Suman Jana},
  title         = {DeepXplore: Automated Whitebox Testing of Deep Learning Systems},
  year          = {2017},
  month         = may,
  abstract      = {Deep learning (DL) systems are increasingly deployed in safety- and security-critical domains including self-driving cars and malware detection, where the correctness and predictability of a system's behavior for corner case inputs are of great importance. Existing DL testing depends heavily on manually labeled data and therefore often fails to expose erroneous behaviors for rare inputs. We design, implement, and evaluate DeepXplore, the first whitebox framework for systematically testing real-world DL systems. First, we introduce neuron coverage for systematically measuring the parts of a DL system exercised by test inputs. Next, we leverage multiple DL systems with similar functionality as cross-referencing oracles to avoid manual checking. Finally, we demonstrate how finding inputs for DL systems that both trigger many differential behaviors and achieve high neuron coverage can be represented as a joint optimization problem and solved efficiently using gradient-based search techniques. DeepXplore efficiently finds thousands of incorrect corner case behaviors (e.g., self-driving cars crashing into guard rails and malware masquerading as benign software) in state-of-the-art DL models with thousands of neurons trained on five popular datasets including ImageNet and Udacity self-driving challenge data. For all tested DL models, on average, DeepXplore generated one test input demonstrating incorrect behavior within one second while running only on a commodity laptop. We further show that the test inputs generated by DeepXplore can also be used to retrain the corresponding DL model to improve the model's accuracy by up to 3%.},
  archiveprefix = {arXiv},
  doi           = {10.1145/3132747.3132785},
  eprint        = {1705.06640},
  file          = {:http\://arxiv.org/pdf/1705.06640v4:PDF},
  groups        = {Neural Networks},
  keywords      = {cs.LG, cs.CR, cs.SE},
  primaryclass  = {cs.LG},
}

@InProceedings{tian2018deeptest,
  author    = {Yuchi Tian and Kexin Pei and Suman Jana and Baishakhi Ray},
  booktitle = {Proceedings of the 40th International Conference on Software Engineering},
  title     = {{DeepTest}},
  year      = {2018},
  month     = {may},
  publisher = {{ACM}},
  doi       = {10.1145/3180155.3180220},
  groups    = {Neural Networks},
}

@Article{pulina2012challenging,
  author    = {Luca Pulina and Armando Tacchella},
  journal   = {AI Communications},
  title     = {Challenging SMT solvers to verify neural networks},
  year      = {2012},
  issn      = {09217126},
  pages     = {117-135},
  volume    = {25},
  doi       = {10.3233/AIC-2012-0525},
  groups    = {Neural Networks},
  publisher = {IOS Press},
}

@InCollection{pulina2010abstraction,
  author    = {Luca Pulina and Armando Tacchella},
  booktitle = {Computer Aided Verification},
  publisher = {Springer Berlin Heidelberg},
  title     = {An Abstraction-Refinement Approach to Verification of Artificial Neural Networks},
  year      = {2010},
  pages     = {243--257},
  doi       = {10.1007/978-3-642-14295-6_24},
  groups    = {Neural Networks},
}

@InProceedings{NIPS2016_980ecd05,
  author    = {Bastani, Osbert and Ioannou, Yani and Lampropoulos, Leonidas and Vytiniotis, Dimitrios and Nori, Aditya and Criminisi, Antonio},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {Measuring Neural Net Robustness with Constraints},
  year      = {2016},
  editor    = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
  publisher = {Curran Associates, Inc.},
  volume    = {29},
  groups    = {Neural Networks},
  url       = {https://proceedings.neurips.cc/paper/2016/file/980ecd059122ce2e50136bda65c25e07-Paper.pdf},
}

@InProceedings{scheibler2015towards,
  author    = {Scheibler, Karsten and Winterer, Leonore and Wimmer, Ralf and Becker, Bernd},
  booktitle = {Methoden und Beschreibungssprachen zur Modellierung und Verifikation von Schaltungen und Systemen},
  title     = {Towards Verification of Artificial Neural Networks},
  year      = {2015},
  pages     = {30--40},
  groups    = {Neural Networks},
}

@InProceedings{jansen2020safe,
  author    = {Jansen, Nils and K√∂nighofer, Bettina and Junges, Sebastian and Serban, Alex and Bloem, Roderick},
  title     = {Safe Reinforcement Learning Using Probabilistic Shields (Invited Paper)},
  year      = {2020},
  publisher = {Schloss Dagstuhl - Leibniz-Zentrum f√ºr Informatik},
  copyright = {Creative Commons Attribution 3.0 Unported license},
  doi       = {10.4230/LIPICS.CONCUR.2020.3},
  groups    = {Reinforcement Learning},
  keywords  = {Safe Reinforcement Learning, Formal Verification, Safe Exploration, Model Checking, Markov Decision Process, Computing methodologies ‚Üí Reinforcement learning, Theory of computation ‚Üí Verification by model checking, Theory of computation ‚Üí Reinforcement learning, Computing methodologies ‚Üí Markov decision processes},
  language  = {en},
}

@Article{miret2020safety,
  author        = {Santiago Miret and Somdeb Majumdar and Carroll Wainwright},
  title         = {Safety Aware Reinforcement Learning (SARL)},
  year          = {2020},
  month         = oct,
  abstract      = {As reinforcement learning agents become increasingly integrated into complex, real-world environments, designing for safety becomes a critical consideration. We specifically focus on researching scenarios where agents can cause undesired side effects while executing a policy on a primary task. Since one can define multiple tasks for a given environment dynamics, there are two important challenges. First, we need to abstract the concept of safety that applies broadly to that environment independent of the specific task being executed. Second, we need a mechanism for the abstracted notion of safety to modulate the actions of agents executing different policies to minimize their side-effects. In this work, we propose Safety Aware Reinforcement Learning (SARL) - a framework where a virtual safe agent modulates the actions of a main reward-based agent to minimize side effects. The safe agent learns a task-independent notion of safety for a given environment. The main agent is then trained with a regularization loss given by the distance between the native action probabilities of the two agents. Since the safe agent effectively abstracts a task-independent notion of safety via its action probabilities, it can be ported to modulate multiple policies solving different tasks within the given environment without further training. We contrast this with solutions that rely on task-specific regularization metrics and test our framework on the SafeLife Suite, based on Conway's Game of Life, comprising a number of complex tasks in dynamic environments. We show that our solution is able to match the performance of solutions that rely on task-specific side-effect penalties on both the primary and safety objectives while additionally providing the benefit of generalizability and portability.},
  archiveprefix = {arXiv},
  eprint        = {2010.02846},
  file          = {:http\://arxiv.org/pdf/2010.02846v1:PDF},
  groups        = {Reinforcement Learning},
  keywords      = {cs.LG, cs.AI},
  primaryclass  = {cs.LG},
}

@InProceedings{287bab4166644802b0f213216f49106f,
  author    = {Mohammed Alshiekh and Roderick Bloem and R{\"u}diger Ehlers and Bettina K{\"o}nighofer and Scott Niekum and Ufuk Topcu},
  booktitle = {Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February 2-7, 2018},
  title     = {Safe Reinforcement Learning via Shielding},
  year      = {2018},
  note      = {32nd AAAI Conference on Artificial Intelligence : AAAI-18, AAAI-18 ; Conference date: 02-02-2018 Through 07-02-2018},
  pages     = {2669--2678},
  groups    = {Reinforcement Learning},
  language  = {English},
  url       = {https://aaai.org/Conferences/AAAI-18/},
}

@InCollection{junges2016safety,
  author    = {Sebastian Junges and Nils Jansen and Christian Dehnert and Ufuk Topcu and Joost-Pieter Katoen},
  booktitle = {Tools and Algorithms for the Construction and Analysis of Systems},
  publisher = {Springer Berlin Heidelberg},
  title     = {Safety-Constrained Reinforcement Learning for {MDPs}},
  year      = {2016},
  pages     = {130--146},
  doi       = {10.1007/978-3-662-49674-9_8},
  groups    = {Reinforcement Learning},
}

@Article{10.5555/2789272.2886795,
  author     = {Garc\'{\i}a, Javier and Fern\'{a}ndez, Fernando},
  journal    = {J. Mach. Learn. Res.},
  title      = {A Comprehensive Survey on Safe Reinforcement Learning},
  year       = {2015},
  issn       = {1532-4435},
  month      = {jan},
  number     = {1},
  pages      = {1437‚Äì1480},
  volume     = {16},
  abstract   = {Safe Reinforcement Learning can be defined as the process of learning policies that maximize the expectation of the return in problems in which it is important to ensure reasonable system performance and/or respect safety constraints during the learning and/or deployment processes. We categorize and analyze two approaches of Safe Reinforcement Learning. The first is based on the modification of the optimality criterion, the classic discounted finite/infinite horizon, with a safety factor. The second is based on the modification of the exploration process through the incorporation of external knowledge or the guidance of a risk metric. We use the proposed classification to survey the existing literature, as well as suggesting future directions for Safe Reinforcement Learning.},
  groups     = {Reinforcement Learning, Surveys},
  issue_date = {January 2015},
  keywords   = {risk sensitivity, safe exploration, reinforcement learning, teacher advice},
  numpages   = {44},
  publisher  = {JMLR.org},
}

@InProceedings{akametalu2014reachability,
  author    = {Anayo K. Akametalu and Jaime F. Fisac and Jeremy H. Gillula and Shahab Kaynama and Melanie N. Zeilinger and Claire J. Tomlin},
  booktitle = {53rd {IEEE} Conference on Decision and Control},
  title     = {Reachability-based safe learning with Gaussian processes},
  year      = {2014},
  month     = {dec},
  publisher = {{IEEE}},
  doi       = {10.1109/cdc.2014.7039601},
  groups    = {Reinforcement Learning},
}

@Article{moldovan2012safe,
  author        = {Teodor Mihai Moldovan and Pieter Abbeel},
  title         = {Safe Exploration in Markov Decision Processes},
  year          = {2012},
  month         = may,
  abstract      = {In environments with uncertain dynamics exploration is necessary to learn how to perform well. Existing reinforcement learning algorithms provide strong exploration guarantees, but they tend to rely on an ergodicity assumption. The essence of ergodicity is that any state is eventually reachable from any other state by following a suitable policy. This assumption allows for exploration algorithms that operate by simply favoring states that have rarely been visited before. For most physical systems this assumption is impractical as the systems would break before any reasonable exploration has taken place, i.e., most physical systems don't satisfy the ergodicity assumption. In this paper we address the need for safe exploration methods in Markov decision processes. We first propose a general formulation of safety through ergodicity. We show that imposing safety by restricting attention to the resulting set of guaranteed safe policies is NP-hard. We then present an efficient algorithm for guaranteed safe, but potentially suboptimal, exploration. At the core is an optimization formulation in which the constraints restrict attention to a subset of the guaranteed safe policies and the objective favors exploration policies. Our framework is compatible with the majority of previously proposed exploration methods, which rely on an exploration bonus. Our experiments, which include a Martian terrain exploration problem, show that our method is able to explore better than classical exploration methods.},
  archiveprefix = {arXiv},
  eprint        = {1205.4810},
  file          = {:http\://arxiv.org/pdf/1205.4810v3:PDF},
  groups        = {Reinforcement Learning},
  keywords      = {cs.LG},
  primaryclass  = {cs.LG},
}

@Article{Fulton_Platzer_2018,
  author       = {Fulton, Nathan and Platzer, Andr√©},
  journal      = {Proceedings of the AAAI Conference on Artificial Intelligence},
  title        = {Safe Reinforcement Learning via Formal Methods: Toward Safe Control Through Proof and Learning},
  year         = {2018},
  month        = {Apr.},
  number       = {1},
  volume       = {32},
  abstractnote = {&lt;p&gt; Formal verification provides a high degree of confidence in safe system operation, but only if reality matches the verified model. Although a good model will be accurate most of the time, even the best models are incomplete. This is especially true in Cyber-Physical Systems because high-fidelity physical models of systems are expensive to develop and often intractable to verify. Conversely, reinforcement learning-based controllers are lauded for their flexibility in unmodeled environments, but do not provide guarantees of safe operation. This paper presents an approach for provably safe learning that provides the best of both worlds: the exploration and optimization capabilities of learning along with the safety guarantees of formal verification. Our main insight is that formal verification combined with verified runtime monitoring can ensure the safety of a learning agent. Verification results are preserved whenever learning agents limit exploration within the confounds of verified control choices as long as observed reality comports with the model used for off-line verification. When a model violation is detected, the agent abandons efficiency and instead attempts to learn a control strategy that guides the agent to a modeled portion of the state space. We prove that our approach toward incorporating knowledge about safe control into learning systems preserves safety guarantees, and demonstrate that we retain the empirical performance benefits provided by reinforcement learning. We also explore various points in the design space for these justified speculative controllers in a simple model of adaptive cruise control model for autonomous cars. &lt;/p&gt;},
  groups       = {Reinforcement Learning},
  url          = {https://ojs.aaai.org/index.php/AAAI/article/view/12107},
}

@InProceedings{gehring2013smart,
  author    = {Gehring, Clement and Precup, Doina},
  booktitle = {Proceedings of the 2013 International Conference on Autonomous Agents and Multi-agent Systems},
  title     = {Smart exploration in reinforcement learning using absolute temporal difference errors},
  year      = {2013},
  pages     = {1037--1044},
  groups    = {Reinforcement Learning},
}

@InProceedings{hans2008safe,
  author       = {Hans, Alexander and Schneega{\ss}, Daniel and Sch{\"a}fer, Anton Maximilian and Udluft, Steffen},
  booktitle    = {ESANN},
  title        = {Safe exploration for reinforcement learning.},
  year         = {2008},
  organization = {Citeseer},
  pages        = {143--148},
  groups       = {Reinforcement Learning},
}

@InProceedings{wu2019shield,
  author    = {Meng Wu and Jingbo Wang and Jyotirmoy Deshmukh and Chao Wang},
  booktitle = {2019 Formal Methods in Computer Aided Design ({FMCAD})},
  title     = {Shield Synthesis for Real: Enforcing Safety in Cyber-Physical Systems},
  year      = {2019},
  month     = {oct},
  publisher = {{IEEE}},
  doi       = {10.23919/fmcad.2019.8894264},
  groups    = {Runtime Enforcement and Shield Synthesis},
}

@Article{koenighofer2017shield,
  author    = {Bettina K√∂nighofer and Mohammed Alshiekh and Roderick Bloem and Laura Humphrey and Robert K√∂nighofer and Ufuk Topcu and Chao Wang},
  journal   = {Formal Methods in System Design},
  title     = {Shield synthesis},
  year      = {2017},
  month     = {sep},
  number    = {2},
  pages     = {332--361},
  volume    = {51},
  doi       = {10.1007/s10703-017-0276-9},
  groups    = {Runtime Enforcement and Shield Synthesis},
  publisher = {Springer Science and Business Media {LLC}},
}

@InProceedings{renard2017runtime,
  author    = {Matthieu Renard and Antoine Rollet and Yli{\`{e}}s Falcone},
  booktitle = {Proceedings of the 24th {ACM} {SIGSOFT} International {SPIN} Symposium on Model Checking of Software},
  title     = {Runtime enforcement using B√ºchi games},
  year      = {2017},
  month     = {jul},
  publisher = {{ACM}},
  doi       = {10.1145/3092282.3092296},
  groups    = {Runtime Enforcement and Shield Synthesis},
}

@InCollection{bloem2015shield,
  author    = {Roderick Bloem and Bettina K√∂nighofer and Robert K√∂nighofer and Chao Wang},
  booktitle = {Tools and Algorithms for the Construction and Analysis of Systems},
  publisher = {Springer Berlin Heidelberg},
  title     = {Shield Synthesis:},
  year      = {2015},
  pages     = {533--548},
  doi       = {10.1007/978-3-662-46681-0_51},
  groups    = {Runtime Enforcement and Shield Synthesis},
}

@InCollection{renard2015enforcement,
  author    = {Matthieu Renard and Yli{\`{e}}s Falcone and Antoine Rollet and Srinivas Pinisetty and Thierry J{\'{e}}ron and Herv{\'{e}} Marchand},
  booktitle = {Theoretical Aspects of Computing - {ICTAC} 2015},
  publisher = {Springer International Publishing},
  title     = {Enforcement of (Timed) Properties with Uncontrollable Events},
  year      = {2015},
  pages     = {542--560},
  doi       = {10.1007/978-3-319-25150-9_31},
  groups    = {Runtime Enforcement and Shield Synthesis},
}

@Article{bauer2011runtime,
  author    = {Andreas Bauer and Martin Leucker and Christian Schallhart},
  journal   = {{ACM} Transactions on Software Engineering and Methodology},
  title     = {Runtime Verification for {LTL} and {TLTL}},
  year      = {2011},
  month     = {sep},
  number    = {4},
  pages     = {1--64},
  volume    = {20},
  doi       = {10.1145/2000799.2000800},
  groups    = {Runtime Enforcement and Shield Synthesis},
  publisher = {Association for Computing Machinery ({ACM})},
}

@Article{bortolussi2016smoothed,
  author    = {Luca Bortolussi and Dimitrios Milios and Guido Sanguinetti},
  journal   = {Information and Computation},
  title     = {Smoothed model checking for uncertain Continuous-Time Markov Chains},
  year      = {2016},
  month     = {apr},
  pages     = {235--253},
  volume    = {247},
  doi       = {10.1016/j.ic.2016.01.004},
  groups    = {Markov Decision Procedures},
  publisher = {Elsevier {BV}},
}

@InCollection{brazdil2015counterexample,
  author    = {Tom{\'{a}}{\v{s}} Br{\'{a}}zdil and Krishnendu Chatterjee and Martin Chmel{\'{\i}}k and Andreas Fellner and Jan K{\v{r}}et{\'{\i}}nsk{\'{y}}},
  booktitle = {Computer Aided Verification},
  publisher = {Springer International Publishing},
  title     = {Counterexample Explanation by Learning Small Strategies in Markov Decision Processes},
  year      = {2015},
  pages     = {158--177},
  doi       = {10.1007/978-3-319-21690-4_10},
  groups    = {Markov Decision Procedures},
}

@Article{huang2014formal,
  author    = {Shaobin Huang and Yuan Cheng and Dapeng Lang and Ronghua Chi and Guofeng Liu},
  journal   = {{PLoS} {ONE}},
  title     = {A Formal Algorithm for Verifying the Validity of Clustering Results Based on Model Checking},
  year      = {2014},
  month     = {mar},
  number    = {3},
  pages     = {e90109},
  volume    = {9},
  doi       = {10.1371/journal.pone.0090109},
  editor    = {Michal Zochowski},
  groups    = {Clustering},
  publisher = {Public Library of Science ({PLoS})},
}

@Article{chouhan2020formal,
  author    = {Aaditya Prakash Chouhan and Gourinath Banda},
  journal   = {Sensors},
  title     = {Formal Verification of Heuristic Autonomous Intersection Management Using Statistical Model Checking},
  year      = {2020},
  month     = {aug},
  number    = {16},
  pages     = {4506},
  volume    = {20},
  doi       = {10.3390/s20164506},
  groups    = {ML Systems},
  publisher = {{MDPI} {AG}},
}

@Article{lee2020towards,
  author    = {Wonyeol Lee and Hangyeol Yu and Xavier Rival and Hongseok Yang},
  journal   = {Proceedings of the {ACM} on Programming Languages},
  title     = {Towards verified stochastic variational inference for probabilistic programs},
  year      = {2020},
  month     = {jan},
  number    = {{POPL}},
  pages     = {1--33},
  volume    = {4},
  doi       = {10.1145/3371084},
  groups    = {ML Systems},
  publisher = {Association for Computing Machinery ({ACM})},
}

@Article{seshia2016towards,
  author        = {Sanjit A. Seshia and Dorsa Sadigh and S. Shankar Sastry},
  title         = {Towards Verified Artificial Intelligence},
  year          = {2016},
  month         = jun,
  abstract      = {Verified artificial intelligence (AI) is the goal of designing AI-based systems that that have strong, ideally provable, assurances of correctness with respect to mathematically-specified requirements. This paper considers Verified AI from a formal methods perspective. We describe five challenges for achieving Verified AI, and five corresponding principles for addressing these challenges.},
  archiveprefix = {arXiv},
  eprint        = {1606.08514},
  file          = {:http\://arxiv.org/pdf/1606.08514v4:PDF},
  groups        = {ML Systems},
  keywords      = {cs.AI},
  primaryclass  = {cs.AI},
}

@Article{bagnall2019certifying,
  author    = {Alexander Bagnall and Gordon Stewart},
  journal   = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
  title     = {Certifying the True Error: Machine Learning in Coq with Verified Generalization Guarantees},
  year      = {2019},
  month     = {jul},
  pages     = {2662--2669},
  volume    = {33},
  doi       = {10.1609/aaai.v33i01.33012662},
  groups    = {ML Systems},
  publisher = {Association for the Advancement of Artificial Intelligence ({AAAI})},
}

@InProceedings{verifai-cav19,
  author    = {Tommaso Dreossi and Daniel J. Fremont and Shromona Ghosh and Edward Kim and Hadi Ravanbakhsh and Marcell Vazquez{-}Chanlatte and Sanjit A. Seshia},
  booktitle = {31st International Conference on Computer Aided Verification (CAV)},
  title     = {{VerifAI:} {A} Toolkit for the Formal Design and Analysis of Artificial Intelligence-Based Systems},
  year      = {2019},
  month     = jul,
  groups    = {ML Systems},
}

@Article{ignatiev2019validating,
  author        = {Alexey Ignatiev and Nina Narodytska and Joao Marques-Silva},
  title         = {On Validating, Repairing and Refining Heuristic ML Explanations},
  year          = {2019},
  month         = jul,
  abstract      = {Recent years have witnessed a fast-growing interest in computing explanations for Machine Learning (ML) models predictions. For non-interpretable ML models, the most commonly used approaches for computing explanations are heuristic in nature. In contrast, recent work proposed rigorous approaches for computing explanations, which hold for a given ML model and prediction over the entire instance space. This paper extends earlier work to the case of boosted trees and assesses the quality of explanations obtained with state-of-the-art heuristic approaches. On most of the datasets considered, and for the vast majority of instances, the explanations obtained with heuristic approaches are shown to be inadequate when the entire instance space is (implicitly) considered.},
  archiveprefix = {arXiv},
  eprint        = {1907.02509},
  file          = {:http\://arxiv.org/pdf/1907.02509v1:PDF},
  groups        = {ML Systems},
  keywords      = {cs.LG, cs.AI, cs.LO},
  primaryclass  = {cs.LG},
}

@Article{barthe2018proving,
  author    = {Gilles Barthe and Thomas Espitau and Benjamin Gr{\'{e}}goire and Justin Hsu and Pierre-Yves Strub},
  journal   = {Proceedings of the {ACM} on Programming Languages},
  title     = {Proving expected sensitivity of probabilistic programs},
  year      = {2018},
  month     = {jan},
  number    = {{POPL}},
  pages     = {1--29},
  volume    = {2},
  doi       = {10.1145/3158145},
  groups    = {ML Systems},
  publisher = {Association for Computing Machinery ({ACM})},
}

@Article{udeshi2019grammar,
  author        = {Sakshi Udeshi and Sudipta Chattopadhyay},
  title         = {Grammar Based Directed Testing of Machine Learning Systems},
  year          = {2019},
  month         = feb,
  abstract      = {The massive progress of machine learning has seen its application over a variety of domains in the past decade. But how do we develop a systematic, scalable and modular strategy to validate machine-learning systems? We present, to the best of our knowledge, the first approach, which provides a systematic test framework for machine-learning systems that accepts grammar-based inputs. Our OGMA approach automatically discovers erroneous behaviours in classifiers and leverages these erroneous behaviours to improve the respective models. OGMA leverages inherent robustness properties present in any well trained machine-learning model to direct test generation and thus, implementing a scalable test generation methodology. To evaluate our OGMA approach, we have tested it on three real world natural language processing (NLP) classifiers. We have found thousands of erroneous behaviours in these systems. We also compare OGMA with a random test generation approach and observe that OGMA is more effective than such random test generation by up to 489%.},
  archiveprefix = {arXiv},
  eprint        = {1902.10027},
  file          = {:http\://arxiv.org/pdf/1902.10027v3:PDF},
  groups        = {ML Systems},
  keywords      = {cs.LG, cs.AI},
  primaryclass  = {cs.LG},
}

@Article{norman2017verification,
  author    = {Gethin Norman and David Parker and Xueyi Zou},
  journal   = {Real-Time Systems},
  title     = {Verification and control of partially observable probabilistic systems},
  year      = {2017},
  month     = {mar},
  number    = {3},
  pages     = {354--402},
  volume    = {53},
  doi       = {10.1007/s11241-017-9269-4},
  groups    = {ML Systems},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{selsam2017developing,
  author        = {Daniel Selsam and Percy Liang and David L. Dill},
  title         = {Developing Bug-Free Machine Learning Systems With Formal Mathematics},
  year          = {2017},
  month         = jun,
  abstract      = {Noisy data, non-convex objectives, model misspecification, and numerical instability can all cause undesired behaviors in machine learning systems. As a result, detecting actual implementation errors can be extremely difficult. We demonstrate a methodology in which developers use an interactive proof assistant to both implement their system and to state a formal theorem defining what it means for their system to be correct. The process of proving this theorem interactively in the proof assistant exposes all implementation errors since any error in the program would cause the proof to fail. As a case study, we implement a new system, Certigrad, for optimizing over stochastic computation graphs, and we generate a formal (i.e. machine-checkable) proof that the gradients sampled by the system are unbiased estimates of the true mathematical gradients. We train a variational autoencoder using Certigrad and find the performance comparable to training the same model in TensorFlow.},
  archiveprefix = {arXiv},
  eprint        = {1706.08605},
  file          = {:http\://arxiv.org/pdf/1706.08605v1:PDF},
  groups        = {ML Systems},
  keywords      = {cs.SE, cs.AI},
  primaryclass  = {cs.SE},
}

@Article{papernot2016towards,
  author        = {Nicolas Papernot and Patrick McDaniel and Arunesh Sinha and Michael Wellman},
  title         = {Towards the Science of Security and Privacy in Machine Learning},
  year          = {2016},
  month         = nov,
  abstract      = {Advances in machine learning (ML) in recent years have enabled a dizzying array of applications such as data analytics, autonomous systems, and security diagnostics. ML is now pervasive---new systems and models are being deployed in every domain imaginable, leading to rapid and widespread deployment of software based inference and decision making. There is growing recognition that ML exposes new vulnerabilities in software systems, yet the technical community's understanding of the nature and extent of these vulnerabilities remains limited. We systematize recent findings on ML security and privacy, focusing on attacks identified on these systems and defenses crafted to date. We articulate a comprehensive threat model for ML, and categorize attacks and defenses within an adversarial framework. Key insights resulting from works both in the ML and security communities are identified and the effectiveness of approaches are related to structural elements of ML algorithms and the data used to train them. We conclude by formally exploring the opposing relationship between model accuracy and resilience to adversarial manipulation. Through these explorations, we show that there are (possibly unavoidable) tensions between model complexity, accuracy, and resilience that must be calibrated for the environments in which they will be used.},
  archiveprefix = {arXiv},
  eprint        = {1611.03814},
  file          = {:http\://arxiv.org/pdf/1611.03814v1:PDF},
  groups        = {ML Systems},
  keywords      = {cs.CR, cs.LG},
  primaryclass  = {cs.CR},
}

@Article{amodei2016concrete,
  author        = {Dario Amodei and Chris Olah and Jacob Steinhardt and Paul Christiano and John Schulman and Dan Man√©},
  title         = {Concrete Problems in AI Safety},
  year          = {2016},
  month         = jun,
  abstract      = {Rapid progress in machine learning and artificial intelligence (AI) has brought increasing attention to the potential impacts of AI technologies on society. In this paper we discuss one such potential impact: the problem of accidents in machine learning systems, defined as unintended and harmful behavior that may emerge from poor design of real-world AI systems. We present a list of five practical research problems related to accident risk, categorized according to whether the problem originates from having the wrong objective function ("avoiding side effects" and "avoiding reward hacking"), an objective function that is too expensive to evaluate frequently ("scalable supervision"), or undesirable behavior during the learning process ("safe exploration" and "distributional shift"). We review previous work in these areas as well as suggesting research directions with a focus on relevance to cutting-edge AI systems. Finally, we consider the high-level question of how to think most productively about the safety of forward-looking applications of AI.},
  archiveprefix = {arXiv},
  eprint        = {1606.06565},
  file          = {:http\://arxiv.org/pdf/1606.06565v2:PDF},
  groups        = {ML Systems},
  keywords      = {cs.AI, cs.LG},
  primaryclass  = {cs.AI},
}

@Article{xu2011robustness,
  author    = {Huan Xu and Shie Mannor},
  journal   = {Machine Learning},
  title     = {Robustness and generalization},
  year      = {2011},
  month     = {nov},
  number    = {3},
  pages     = {391--423},
  volume    = {86},
  doi       = {10.1007/s10994-011-5268-1},
  groups    = {ML Systems},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{tran2020verificationa,
  author    = {Hoang-Dung Tran and Weiming Xiang and Taylor T. Johnson},
  journal   = {{IEEE} Design {\&} Test},
  title     = {Verification Approaches for Learning-Enabled Autonomous Cyber-Physical Systems},
  year      = {2020},
  pages     = {1--1},
  doi       = {10.1109/mdat.2020.3015712},
  groups    = {Cyber-Physical Systems},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Article{bolbot2019vulnerabilities,
  author    = {Victor Bolbot and Gerasimos Theotokatos and Luminita Manuela Bujorianu and Evangelos Boulougouris and Dracos Vassalos},
  journal   = {Reliability Engineering {\&} System Safety},
  title     = {Vulnerabilities and safety assurance methods in Cyber-Physical Systems: A comprehensive review},
  year      = {2019},
  month     = {feb},
  pages     = {179--193},
  volume    = {182},
  doi       = {10.1016/j.ress.2018.09.004},
  groups    = {Cyber-Physical Systems},
  publisher = {Elsevier {BV}},
}

@InProceedings{ivanov2019verisig,
  author    = {Radoslav Ivanov and James Weimer and Rajeev Alur and George J. Pappas and Insup Lee},
  booktitle = {Proceedings of the 22nd {ACM} International Conference on Hybrid Systems: Computation and Control},
  title     = {Verisig},
  year      = {2019},
  month     = {apr},
  publisher = {{ACM}},
  doi       = {10.1145/3302504.3311806},
  groups    = {Cyber-Physical Systems},
}

@InProceedings{nejati2019evaluating,
  author    = {Shiva Nejati and Khouloud Gaaloul and Claudio Menghi and Lionel C. Briand and Stephen Foster and David Wolfe},
  booktitle = {Proceedings of the 2019 27th {ACM} Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  title     = {Evaluating model testing and model checking for finding requirements violations in Simulink models},
  year      = {2019},
  month     = {aug},
  publisher = {{ACM}},
  doi       = {10.1145/3338906.3340444},
  groups    = {Cyber-Physical Systems},
}

@InCollection{platzer2019logical,
  author    = {Andr{\'{e}} Platzer},
  booktitle = {Quantitative Evaluation of Systems},
  publisher = {Springer International Publishing},
  title     = {The Logical Path to Autonomous Cyber-Physical Systems},
  year      = {2019},
  pages     = {25--33},
  doi       = {10.1007/978-3-030-30281-8_2},
  groups    = {Cyber-Physical Systems},
}

@InProceedings{sun2019formal,
  author    = {Xiaowu Sun and Haitham Khedr and Yasser Shoukry},
  booktitle = {Proceedings of the 22nd {ACM} International Conference on Hybrid Systems: Computation and Control},
  title     = {Formal verification of neural network controlled autonomous systems},
  year      = {2019},
  month     = {apr},
  publisher = {{ACM}},
  doi       = {10.1145/3302504.3311802},
  groups    = {Cyber-Physical Systems},
}

@Article{tran2019safety,
  author    = {Hoang-Dung Tran and Feiyang Cai and Manzanas Lopez Diego and Patrick Musau and Taylor T. Johnson and Xenofon Koutsoukos},
  journal   = {{ACM} Transactions on Embedded Computing Systems},
  title     = {Safety Verification of Cyber-Physical Systems with Reinforcement Learning Control},
  year      = {2019},
  month     = {oct},
  number    = {5s},
  pages     = {1--22},
  volume    = {18},
  doi       = {10.1145/3358230},
  groups    = {Cyber-Physical Systems},
  publisher = {Association for Computing Machinery ({ACM})},
}

@Article{duan2018systematic,
  author    = {Pengfei Duan and Ying Zhou and Xufang Gong and Bixin Li},
  journal   = {{IEEE} Access},
  title     = {A Systematic Mapping Study on the Verification of Cyber-Physical Systems},
  year      = {2018},
  pages     = {59043--59064},
  volume    = {6},
  doi       = {10.1109/access.2018.2872015},
  groups    = {Cyber-Physical Systems, Surveys},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@InProceedings{tuncali2018reasoning,
  author    = {Cumhur Erkan Tuncali and James Kapinski and Hisahiro Ito and Jyotirmoy V. Deshmukh},
  booktitle = {Proceedings of the 55th Annual Design Automation Conference},
  title     = {Reasoning about safety of learning-enabled components in autonomous cyber-physical systems},
  year      = {2018},
  month     = {jun},
  publisher = {{ACM}},
  doi       = {10.1145/3195970.3199852},
  groups    = {Cyber-Physical Systems},
}

@InCollection{xiang2018reachable,
  author    = {Weiming Xiang and Diego Manzanas Lopez and Patrick Musau and Taylor T. Johnson},
  booktitle = {Safe, Autonomous and Intelligent Vehicles},
  publisher = {Springer International Publishing},
  title     = {Reachable Set Estimation and Verification for Neural Network Models of Nonlinear Dynamic Systems},
  year      = {2018},
  month     = {nov},
  pages     = {123--144},
  doi       = {10.1007/978-3-319-97301-2_7},
  groups    = {Cyber-Physical Systems},
}

@InProceedings{raj2017testing,
  author    = {Sunny Raj and Sumit Kumar Jha and Arvind Ramanathan and Laura L. Pullum},
  booktitle = {Proceedings of the Thirteenth {ACM} International Conference on Embedded Software 2017 Companion - {EMSOFT} {\textquotesingle}17},
  title     = {Testing autonomous cyber-physical systems using fuzzing features from convolutional neural networks},
  year      = {2017},
  publisher = {{ACM} Press},
  doi       = {10.1145/3125503.3125568},
  groups    = {Cyber-Physical Systems},
}

@InProceedings{7459413,
  author    = {Ramanathan, Arvind and Pullum, Laura L. and Hussain, Faraz and Chakrabarty, Dwaipayan and Jha, Sumit Kumar},
  booktitle = {2016 Design, Automation Test in Europe Conference Exhibition (DATE)},
  title     = {Integrating symbolic and statistical methods for testing intelligent systems: Applications to machine learning and computer vision},
  year      = {2016},
  pages     = {786-791},
  groups    = {Cyber-Physical Systems},
}

@InProceedings{jha2011modeling,
  author       = {Jha, Sumit Kumar and Sukthankar, Gita},
  booktitle    = {Proceedings of the NIST/NSF/USCAR Workshop on Developing Dependable and Secure Automotive Cyber-Physical Systems from Components},
  title        = {Modeling and Verifying Intelligent Automotive Cyber-Physical Systems},
  year         = {2011},
  organization = {Citeseer},
  pages        = {1--3},
  groups       = {Cyber-Physical Systems},
}

@Article{harel2019labor,
  author    = {David Harel and Assaf Marron and Ariel Rosenfeld and Moshe Vardi and Gera Weiss},
  journal   = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
  title     = {Labor Division with Movable Walls: Composing Executable Specifications with Machine Learning and Search (Blue Sky Idea)},
  year      = {2019},
  month     = {jul},
  pages     = {9770--9774},
  volume    = {33},
  doi       = {10.1609/aaai.v33i01.33019770},
  groups    = {Executable Specifications},
  publisher = {Association for the Advancement of Artificial Intelligence ({AAAI})},
}

@Article{dreossi2019compositional,
  author    = {Tommaso Dreossi and Alexandre Donz{\'{e}} and Sanjit A. Seshia},
  journal   = {Journal of Automated Reasoning},
  title     = {Compositional Falsification of Cyber-Physical Systems with Machine Learning Components},
  year      = {2019},
  month     = {jan},
  number    = {4},
  pages     = {1031--1053},
  volume    = {63},
  doi       = {10.1007/s10817-018-09509-5},
  groups    = {Integrated Cyber-Physical Systems},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{balasubramaniyan2016design,
  author    = {Sreram Balasubramaniyan and Seshadhri Srinivasan and Furio Buonopane and B. Subathra and J√ºri Vain and Srini Ramaswamy},
  journal   = {Microprocessors and Microsystems},
  title     = {Design and verification of Cyber-Physical Systems using {TrueTime}, evolutionary optimization and {UPPAAL}},
  year      = {2016},
  month     = {may},
  pages     = {37--48},
  volume    = {42},
  doi       = {10.1016/j.micpro.2015.12.006},
  groups    = {Integrated Cyber-Physical Systems},
  publisher = {Elsevier {BV}},
}

@InCollection{chen2016towards,
  author    = {Yuqi Chen and Christopher M. Poskitt and Jun Sun},
  booktitle = {{FM} 2016: Formal Methods},
  publisher = {Springer International Publishing},
  title     = {Towards Learning and Verifying Invariants of Cyber-Physical Systems by Code Mutation},
  year      = {2016},
  pages     = {155--163},
  doi       = {10.1007/978-3-319-48989-6_10},
  groups    = {Integrated Cyber-Physical Systems},
}

@InProceedings{gol2014formal,
  author    = {Ebru Aydin Gol and Ezio Bartocci and Calin Belta},
  booktitle = {53rd {IEEE} Conference on Decision and Control},
  title     = {A formal methods approach to pattern synthesis in reaction diffusion systems},
  year      = {2014},
  month     = {dec},
  publisher = {{IEEE}},
  doi       = {10.1109/cdc.2014.7039367},
  groups    = {Pattern Recognition},
}

@TechReport{gu2020combining,
  author   = {Gu, Rong and Enoiu, Eduard Paul and Seceleanu, Cristina and Lundqvist, Kristina},
  title    = {Combining Model Checking and Reinforcement Learning for Scalable Mission Planning of Autonomous Agents},
  year     = {2020},
  abstract = {The problem of mission planning for multiple autonomous agents, including path planning and task scheduling, is often complex. Recent efforts aiming at solving this problem have explored ways of using formal methods to synthesize mission plans that satisfy various requirements. However, when the number of agents grows or requirements include real-time constraints, the complexity of the problem increases to the extent that current algorithmic formal methods cannot handle. In this paper, we propose a novel approach called MCRL, which overcomes this shortcoming by integrating model checking and reinforcement learning techniques. Our approach employs timed automata and timed computation tree logic to describe the autonomous agents' behavior and requirements, and trains the model by a reinforcement learning algorithm, namely Q-learning, to populate a table used to restrict the state space of the model. MCRL combines the ability of model checking to synthesize verifiable mission plans, and the exploration and exploitation capabilities of Q-learning to alleviate the state-space-explosion problem of exhaustive model checking. Our method provides a means to synthesize mission plans for autonomous systems whose complexity exceeds the scalability boundaries of exhaustive model checking, but also to analyze and verify synthesized mission plans in order to ensure given requirements. We evaluate the proposed method on various relevant scenarios involving autonomous agents, and also present and discuss comparisons with other methods and tools.},
  groups   = {Planning},
  keywords = {autonomous agents, mission planning, model checking, reinforcement learning},
  pages    = {10},
  school   = {M√§lardalen University, Embedded Systems},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:ML for FM\;2\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:Tool and Configuration Selection\;2\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:Synthesis and Repair\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:Formalisation and Specifications\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:Feature Selection\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:Tooling Analysis and Data Mining\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:Model Checking\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:Automated Theorem Proving\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:Invariant Learning\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:ML for General Software Development\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:AI for Formal Software Development\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:FM for ML\;2\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:Neural Networks\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:Reinforcement Learning\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:Runtime Enforcement and Shield Synthesis\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:Markov Decision Procedures\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:Clustering\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:ML Systems\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:Cyber-Physical Systems\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:Integrated\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:Executable Specifications\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:Integrated Cyber-Physical Systems\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:Planning\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:Pattern Recognition\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:Surveys\;0\;1\;0xffff00ff\;\;\;;
1 StaticGroup:Unlisted\;0\;1\;0xff0000ff\;\;\;;
}
